import streamlit as st
import tempfile
import cv2
import os
import openai
from PIL import Image
from datetime import timedelta

# --- Sidebar: API Key å…¥åŠ› ---
st.sidebar.title("ğŸ”‘ API Key")
openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")

# --- ã‚¢ãƒ—ãƒªã®ãƒ˜ãƒƒãƒ€ãƒ¼ ---
st.set_page_config(page_title="å‹•ç”»è¦ç´„ with GPT-4V", layout="wide")
st.title("ğŸ¥ GPT-4Vã§è‡ªå‹•å‹•ç”»è¦ç´„")
st.caption("å‹•ç”»å†…ã®å‹•ããŒå¤§ãã„ã‚·ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã€ç”»åƒã§è¦ç´„ã™ã‚‹ã‚¢ãƒ—ãƒª")

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
uploaded_file = st.file_uploader("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ (mp4, mov)", type=["mp4", "mov"])

if uploaded_file and openai_api_key:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
        tmp.write(uploaded_file.read())
        video_path = tmp.name

    st.video(uploaded_file)
    st.info("ğŸ” å‹•ããŒå¤§ãã„ã‚·ãƒ¼ãƒ³ã‚’è§£æä¸­...ï¼ˆå°‘ã€…ãŠå¾…ã¡ãã ã•ã„ï¼‰")

    # --- OpenCVã§å‹•ç”»å‡¦ç† ---
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    interval = int(fps * 2)  # 2ç§’ãŠãã«ãƒ•ãƒ¬ãƒ¼ãƒ æ¯”è¼ƒ
    prev_frame = None
    frame_diffs = []
    selected_frames = []

    frame_idx = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if frame_idx % interval == 0:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            if prev_frame is not None:
                diff = cv2.absdiff(prev_frame, gray)
                score = diff.sum()
                frame_diffs.append((frame_idx, score, frame))
            prev_frame = gray
        frame_idx += 1
    cap.release()

    # --- å‹•ããŒå¤§ãã„ä¸Šä½5ã‚·ãƒ¼ãƒ³æŠ½å‡º ---
    top_diffs = sorted(frame_diffs, key=lambda x: x[1], reverse=True)[:5]
    st.success(f"âœ… å‹•ããŒå¤§ãã„ã‚·ãƒ¼ãƒ³ã‚’ {len(top_diffs)} å€‹æ¤œå‡ºã—ã¾ã—ãŸ")

    # --- GPT-4V ã§ç”»åƒã”ã¨ã«è¦ç´„ ---
    openai.api_key = openai_api_key

    cols = st.columns(1)
    for idx, (f_idx, score, frame) in enumerate(top_diffs):
        timestamp = str(timedelta(seconds=int(f_idx / fps)))
        image_path = f"frame_{idx}.jpg"
        cv2.imwrite(image_path, frame)
        image = Image.open(image_path)

        with st.container():
            st.subheader(f"ğŸ•’ ã‚·ãƒ¼ãƒ³ {idx + 1}ï¼ˆ{timestamp}ï¼‰")
            st.image(image, caption=f"ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¿ã‚¤ãƒ : {timestamp}", use_column_width=True)

            # --- GPT-4Vã«ã‚ˆã‚‹ç”»åƒè¦ç´„ ---
            with open(image_path, "rb") as img_file:
                response = openai.chat.completions.create(
                    model="gpt-4-vision-preview",
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant that summarizes visual scenes."},
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "ã“ã®ã‚·ãƒ¼ãƒ³ã§ã¯ä½•ãŒèµ·ãã¦ã„ã¾ã™ã‹ï¼Ÿæ—¥æœ¬èªã§ç°¡å˜ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_file.read().encode('base64').decode()}"}}
                            ]
                        }
                    ],
                    max_tokens=100
                )
                caption = response.choices[0].message.content
                st.info(f"ğŸ§  GPTã®è§£èª¬: {caption}")

        os.remove(image_path)
else:
    st.warning("ğŸ”¼ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¨ OpenAI API Key ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
