# streamlit_app.py
import streamlit as st
import openai
import base64
import os
import tempfile
import subprocess
from PIL import Image
from io import BytesIO

st.set_page_config(page_title="YouTube Scene Summarizer", layout="wide")
st.title("ğŸ¥ GPTã«ã‚ˆã‚‹YouTubeå‹•ç”»ã‚·ãƒ¼ãƒ³è§£èª¬")

# Sidebar for API keys
openai_api_key = st.sidebar.text_input("ğŸ”‘ OpenAI API Key", type="password")

if not openai_api_key:
    st.warning("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    st.stop()

openai.api_key = openai_api_key

# Upload YouTube video file (already downloaded)
video_file = st.file_uploader("YouTubeå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆMP4ï¼‰", type=["mp4"])

if video_file:
    # Save video to temp file
    temp_video = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    temp_video.write(video_file.read())
    temp_video_path = temp_video.name

    st.video(temp_video_path)

    if st.button("ã‚·ãƒ¼ãƒ³è§£æã‚’é–‹å§‹"):
        st.info("ç”»åƒã‚’æŠ½å‡ºã—ã¦ã„ã¾ã™... ğŸï¸")

        # Extract 1 image every 10 seconds
        output_dir = tempfile.mkdtemp()
        output_pattern = os.path.join(output_dir, "scene_%03d.jpg")

        command = [
            "ffmpeg", "-i", temp_video_path,
            "-vf", "fps=1/10",
            output_pattern
        ]
        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

        scene_files = sorted([f for f in os.listdir(output_dir) if f.endswith(".jpg")])

        st.success(f"{len(scene_files)} æšã®ç”»åƒã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚GPTã«ã‚ˆã‚‹è§£èª¬ã‚’ç”Ÿæˆä¸­... ğŸ§ ")

        for i, scene_file in enumerate(scene_files):
            with open(os.path.join(output_dir, scene_file), "rb") as img_file:
                img_bytes = img_file.read()
                b64_img = base64.b64encode(img_bytes).decode()

            # GPT-4Vè§£èª¬
            st.image(img_bytes, caption=f"ã‚·ãƒ¼ãƒ³ {i+1}", width=480)
            with st.spinner("GPTãŒè§£èª¬ä¸­..."):
                try:
                    response = openai.chat.completions.create(
                        model="gpt-4-vision-preview",
                        messages=[
                            {
                                "role": "user",
                                "content": [
                                    {"type": "text", "text": "ã“ã®ç”»åƒã«ã¯ä½•ãŒæ˜ ã£ã¦ã„ã¦ã€ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹æ—¥æœ¬èªã§ç°¡å˜ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"},
                                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64_img}"}}
                                ]
                            }
                        ],
                        max_tokens=300
                    )
                    explanation = response.choices[0].message.content
                    st.markdown(f"**ğŸ§  GPTã®è§£èª¬ï¼š** {explanation}")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

        st.success("âœ… ã™ã¹ã¦ã®ã‚·ãƒ¼ãƒ³ã®è§£èª¬ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
