import streamlit as st
import openai
import ffmpeg
import pytube
import whisper
import os
import tempfile
import re
from moviepy.editor import VideoFileClip
from pydub import AudioSegment

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.title("ğŸ”§ è¨­å®š")
openai_api_key = st.sidebar.text_input("OpenAI APIã‚­ãƒ¼", type="password")

if not openai_api_key:
    st.warning("ã¾ãšã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.stop()
else:
    openai.api_key = openai_api_key

# --- ã‚¿ã‚¤ãƒˆãƒ« ---
st.title("ğŸ¥ YouTubeå‹•ç”»å®Ÿæ³ + GPT-4 è§£èª¬")

# --- URLå…¥åŠ› ---
url = st.text_input("YouTubeå‹•ç”»ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# --- YouTube Video ID æŠ½å‡ºé–¢æ•° ---
def get_video_id(url):
    match = re.search(r"(?:v=|youtu\.be/)([a-zA-Z0-9_-]{11})", url)
    return match.group(1) if match else None

# --- Whisperã§æ–‡å­—èµ·ã“ã— ---
def transcribe_audio(audio_path):
    model = whisper.load_model("base")  # "base"ãƒ¢ãƒ‡ãƒ«ã§OKï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ï¼‰
    result = model.transcribe(audio_path)
    return result["text"]

# --- éŸ³å£°æŠ½å‡ºã¨æ–‡å­—èµ·ã“ã— ---
def process_video(url):
    # YouTubeå‹•ç”»ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    yt = pytube.YouTube(url)
    stream = yt.streams.filter(file_extension="mp4").first()
    video_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    stream.download(output_path=video_file.name)

    # å‹•ç”»ã‚’éŸ³å£°ã«å¤‰æ›
    audio_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
    audio_file_path = audio_file.name
    video_clip = VideoFileClip(video_file.name)
    audio_clip = video_clip.audio
    audio_clip.write_audiofile(audio_file_path)

    # Whisperã§éŸ³å£°ã‹ã‚‰æ–‡å­—èµ·ã“ã—
    transcription = transcribe_audio(audio_file_path)
    
    return transcription

# --- GPTã§è§£èª¬ç”Ÿæˆ ---
def generate_explanation(text):
    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯ã‚¹ãƒãƒ¼ãƒ„å®Ÿæ³ã‚„ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã‚’è¡Œã†ãƒ—ãƒ­ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
        {"role": "user", "content": f"æ¬¡ã®æ–‡å­—èµ·ã“ã—ã‚’åŸºã«ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è§£èª¬ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„:\n\n{text}"}
    ]
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=messages
    )
    return response.choices[0].message.content

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
if url:
    video_id = get_video_id(url)
    if video_id:
        st.video(url)  # å‹•ç”»å†ç”Ÿ

        st.subheader("ğŸ“„ å­—å¹•ã®è§£èª¬")
        
        with st.spinner("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­..."):
            transcription = process_video(url)
        
        st.write("**æ–‡å­—èµ·ã“ã—çµæœï¼š**")
        st.write(transcription[:1500])  # æœ€åˆã®1500æ–‡å­—ã ã‘è¡¨ç¤º

        with st.spinner("GPTãŒè§£èª¬ä¸­..."):
            explanation = generate_explanation(transcription)
        
        st.subheader("ğŸ¤ è§£èª¬")
        st.write(explanation)  # GPTã«ã‚ˆã‚‹è§£èª¬
    else:
        st.error("ç„¡åŠ¹ãªYouTube URLã§ã™ã€‚æ­£ã—ã„URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
